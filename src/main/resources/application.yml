spring:
  application:
    name: q-it-llm-client
  mvc:
    servlet:
      path: /api/v1
  ai:
    ollama:
      base-url: http://localhost:11434  # Ollama ?? URL
      init:
        pull-model-strategy: never  # ?? ??? ? ?? ?? ?? (never, always, if-not-exists)
      chat:
        model: llama3.1:8b  # ??? ?? ??
        options:
          temperature: 0.7  # ??? ??: ???? ???? ?? ??
          max-tokens: 1024  # ?? ?? ? ??
